---
title: "Module09: Metagenomics"
author: "Matthew St. Lawrence"
date: "2022-11-17"
output: github_document
---

## 2.1Biom-Format

```{r}
#This demonstrates how to import a biom file.
#For the analysis to take place, we need to import as a biom file and convert to 
#a biom2MRexperiment file. 

library(tidyverse)
library(metagenomeSeq)
library(biomformat)
library(interactiveDisplay)

biom_file <- system.file("extdata", "min_sparse_otu_table.biom",
                         package = "biomformat")

b <- read_biom(biom_file)
biom2MRexperiment(b)
```
An example of data file conversion is detailed below:

```{r}
#loads data
data(mouseData)

#Creates biom object and writes data to file.
b <- MRexperiment2biom(mouseData)
write_biom(b, biom_file = "~/Desktop/otu_table.biom")
```

## 2.2: Loading Count Data

This package requires a matrix, with features on one axis and samples on another.

```{r}
#Loads data
dataDirectory <- system.file("extdata", package = "metagenomeSeq")

#Loads count data and displays dimensions
lung = loadMeta(file.path(dataDirectory, "CHK_NAME.otus.count.csv"))
dim(lung$counts)
```
## 2.3: Loading Taxonomy

the code below loads the annotated taxonomy. It is very very important that
the taxa annotations and OTUs are in the same order as the matrix rows so that
the annotations align with the correct OTU.

```{r}
#Reads taxonomy file into working memory.
taxa <- read.delim(file.path(dataDirectory, "CHK_otus.taxonomy.csv"),
                   stringsAsFactors = FALSE)
```

## 2.4: Loading Metadata

Pheno data can be loaded in for additional annotation. Metadata is loaded in by
the following method:

```{r}
#Loads pheno data into working memeory
clin = loadPhenoData(file.path(dataDirectory, "CHK_clinical.csv"),
                     tran = TRUE)

#Matches column names in count matrix to the rownames in pheno data.
ord = match(colnames(lung$counts), rownames(clin))

#Displays matched data frame.
clin = clin[ord, ]
head(clin[1:2, ])
```

## 2.5: Creating a MRexperiment Object

A count matrix, phenoData (as a dataframe) and featureData (as a dataframe)
are all arguments needed to create a MRexperiment object. This is performed by 
the code chunk below:

```{r}
#Turns phenodata into a dataframe
phenotypeData = AnnotatedDataFrame(clin)
print(phenotypeData)

#Turns the feature data into a dataframe
OTUdata = AnnotatedDataFrame(taxa)
print(OTUdata)

#Creates the object
obj = newMRexperiment(lung$counts, phenoData = phenotypeData, 
                      featureData = OTUdata)

print(obj)
```

## 2.6: Example Datasets

Once data is imported using the method described above, normalization, statistical
tests, and visualizations can be created. The human lung microbiome data set will
be imported and analyzed, along with a mouse gut biome data set.

```{r}
#Displays example datasets
data(lungData)
print(lungData)

data(mouseData)
print(mouseData)
```

## Useful Commands

Some useful commmands when handling phenotype, feature, and count matrix data are detailed below:

```{r}
#Phenotype
phenoData(obj)
head(pData(obj), n = 3)

#Feature
featureData(obj)
head(fData(obj)[, -c(2, 10)], 3)

#Count Matrix - Accesses raw or normalized counts
head(MRcounts(obj[,1:2]))

#MRexperiment class objects can be easily subsetted

#This line filters for features associates with rows in the count matrix where
#the count is greater than or equal to 100.
featuresToKeep = which(rowSums(obj) >= 100)

#This line filters the object for the metadata classification 'Smoker'
samplesToKeep = which(pData(obj)$SmokingStatus == "Smoker")

#This creates a new object out of the filtered old objects.
obj_smokers = obj[featuresToKeep, samplesToKeep]
print(obj_smokers)
head(pData(obj_smokers), n = 3)
```

Scaling factors can also be applied as normalization using the normFactors method

```{r}
#Okay so here normFactors is basically just opening up another attribute for the 
#object that we are filling with a normal distribution using rnorm()
head(normFactors(obj))

normFactors(obj) <- rnorm(ncol(obj))
head(normFactors(obj))

#Another attribute we can access is sequencing depth using libSize()
libSize(obj) <- rnorm(ncol(obj))
head(libSize(obj))
```

Data can be filtered in order to maintain a threshold of minimum depth, so 
shallower reads are excluded as noise:

```{r}
#Filters mouse data based on read depth.
data(mouseData)
filterData(mouseData, present = 10, depth = 1000)
```

MRexperiments objects can be merged together:

```{r}
data(mouseData)

#Merges two instances of the mouse data dataset to demonstrate the merge function.
newobj = mergeMRexperiments(mouseData, mouseData)
print(newobj)
```

# 3: Normalization

Because coverage varies across samples, normalization is required to make each
sample comparable to one another. cumNorm() is a function which will normalize
using scaling factors that are calculated by the number of counts up to a 
particular percentile.


## 3.1: Calculating Normalization Factors

First step is to figure out which percentile will be best for determining 
normalization counts. 

```{r}
#imports the data and calculates the appropriate percentile.
#p can also be manually specified.
data(lungData)
p = cumNormStatFast(lungData)

#This line calculates the scaling factors for the lung dataset by applying p.
lungData = cumNorm(lungData, p = p)
```


### 3.1.1: Calculating Normalization using Wrench

This will take the argument 'condition' instead of 'p'. This will separate
samples into phenotypic groups of interest. This method is generally preferred
over cumulative normalization. Otherwise this will generally perform similar to 
cumNorm().

```{r}
#Uses a feature of the dataset as the conditions
#Then, normalizes data based on that condition.
condition = mouseData$diet
mouseData = wrenchNorm(mouseData, condition = condition)
```

## 3.2: Exporting Data

The normalized count matrices calculated above can be exported by the following
method, along with sample statistics: 

```{r}
#Export normalized count matrices
mat = MRcounts(lungData, norm = TRUE, log = TRUE)[1:5, 1:5]
exportMat(mat, file = file.path(dataDirectory, "tmp.tsv"))

#Export sample statistics
exportStats(lungData[, 1:5], file = file.path(dataDirectory, "tmp.tsv"))

#View exported statistics of all samples
head(read.csv(file = file.path(dataDirectory, "tmp.tsv"), sep = "\t"))
```

# 4: Statistical Testing

In this process we are going to observed and address the effects of under-sampling
on detecting differentially abundant features (OTUs, genes). 


## 4.1: Zero-Inflated Log-Normal Mixture Model for each Feature

Zero-Inflated model: tries to take into account excess zeros in the data set. 
They create two separate models:
 -The count model
 -the excess zeros

Count data should never be negative and any modeling approach which does that is
bad. fitfeatureModel is the current recommended zero-inflation feature model to use.

 
### 4.1.1: Example using fitFeatureModel for Differential Abundance Testing

```{r}
#Filters out missing data, filters for read depth, then normalizes data
data(lungData)
lungData = lungData[, -which(is.na(pData(lungData)$SmokingStatus))]
lungData = filterData(lungData, present = 30, depth = 1)
lungData = cumNorm(lungData, p = 0.5)

#Models filtered data
pd <- pData(lungData)
mod <- model.matrix( ~1 + SmokingStatus, data = pd)
lungres1 = fitFeatureModel(lungData, mod)
head(MRcoefs(lungres1))
```

## 4.2: Zero-Inflated Gaussian Mixture Model

Detection of feature is directly linked to depth of coverage. Higher coverages
means higher number of features detected. This method of modeling was created
to account for missing features.


### 4.2.1: Example using fitZig for differential Abundance Testing

Devs recommend removing features with less than the average number of effective
samples in all features. 

Features = variables in the metadata.

```{r}
data(lungData)
controls = grep("Extraction.Control", pData(lungData)$SampleType)
lungTrim = lungData[, -controls]

#Remove features not present in many samples.
rareFeatures  = which(rowSums(MRcounts(lungTrim) > 0) < 10)
lungTrim = lungTrim[-rareFeatures, ]


lungp = cumNormStat(lungTrim, pFlag = TRUE, main = "Trimmed lung data")

lungTrim = cumNorm(lungTrim, p = lungp)

```

zigControl determines default settings. To use the functions produced by this
model, the final matrix model needs to be extracted using res$fit$design

```{r}
smokingStatus = pData(lungTrim)$SmokingStatus
bodySite = pData(lungTrim)$SampleType

normFactor = normFactors(lungTrim)
normFactor = log2(normFactor/median(normFactor) + 1)

mod = model.matrix(~smokingStatus + bodySite + normFactor)
settings = zigControl(maxit = 10, verbose = TRUE)

fit = fitZig(obj = lungTrim, mod = mod, useCSSoffset = FALSE,
             control = settings)
```

### 4.2.3: Exporting Fits

Three functions can be used to export data: MRcoefs, MRtable, MRfulltable.

By variable: controls which coefficients are of interest. 
Coef: determines the display.

```{r}
#Splits the features in taxa based on presence of ";"
#I'm not quite sure what the function part of this does.
taxa = sapply(strsplit(as.character(fData(lungTrim)$taxa), split = ";"), 
              function(i){i[length(i)]})

#Shows which feature contributes significantly to the metadata feature being
#analyzed.
head(MRcoefs(fit, taxa = taxa, coef = 2))
```


## 4.3: Time Series Analysis

Helps calculate time series for when the bacteria might be differently abundent.
Fitting is performed using smoothing splines ANOVA. Really good analysis to do 
if you have many timepoints. 

If you use this, you need to cite: "Finding Regions of Interest in High Throughput
Genomics Data using Smoothing Splines."


## 4.4: Log Normal Permutation Test

Standard log normal linear model.

```{r}
coeffOfInterest = 2
res = fitLogNormal(obj = lungTrim, mod = mod, useCSSoffset = FALSE,
                   B = 10, coef = coeffOfInterest)

#Extract p-values
adjustedPvalues = p.adjust(res$p, method = "fdr")

#Extract the absolute fold-change estimates
foldChange = abs(res$fit$coef[, coeffOfInterest])

#Determine features still significant and order by
sigList = which(adjustedPvalues <= 0.05)
sigList = sigList[order(foldChange[sigList])]

#Prints the top taxa associated with the coefficient of interest.
head(taxa[sigList])
```

## 4.5: Presence-Absence Testing

Essentially poses the question "Is the proportional difference of a given feature
between samples is significant.". Uses Fisher's exact test and calculates p-values.
This process is handled by the function fitPA().

```{r}
classes = pData(mouseData)$diet

res = fitPA(mouseData[1:5, ], cl = classes)
head(res)
```


## 4.6: Discovery Odds Ratio Testing
Tests to see if the proportion of counts between a specific feature and all 
counts are similar/comparable between groups. This test is handled by the function
fitDO()

```{r}
classes = pData(mouseData)$diet

res = fitDO(mouseData[1:100, ], cl = classes, norm = FALSE, log = FALSE)
head(res)
```


## 4.7: Feature Correlations
This is essentially a regression modeling which tests the correlation of abundance 
features.

```{r}
cors = correlationTest(mouseData[55:60, ], norm = FALSE, log = FALSE)
head(cors)
```

## 4.8: Unique OTUs or Features

Creates a table to features localized to only some groups, while not being
present in others.

```{r}
cl = pData(mouseData)[["diet"]]
uniqueFeatures(mouseData, cl, nsamples = 10, nreads = 100)
```

# 5: Aggregating Counts

There are functions which can aggregate the count matrix. The example below
aggregates data specifically by taxonomy.

```{r}
obj = aggTax(mouseData, lvl = "phylum", out = "matrix")
head(obj[1:5, 1:5])
```

Aggregation of samples can be done with other data found in the MRexperiment
object.

```{r}
obj = aggSamp(mouseData, fct = "mouseID", out = "matrix")
head(obj[1:5, 1:5])
```

# 6: Visualization of Features

metagenomeSeq has several plotting functions which further describes the overall
structure of the data.


## 6.1: Interactive Display

Using the interactive display option will open a browser session with interactive
plots.

```{r}
#require(interactiveDisplay) 
#display(mouseData)
```


## 6.2: Structural Overview

A good place to start for most studies is to compare abundance composition across
sample or feature phenotypes. We can do this 5 different types of ways:

  -plotMRheatmap: heatmap of abundance estimates
  -plotCorr: heatmap of pairwise correlations
  -plotOrd: PCS / CMDS components
  -plotRare: plot rarefaction effect
  -plotBubble: contingency table style plot

Below demonstrates the visualization using heatmap and hierarchical clustering 
of log2 transformed counts for the 200 OTUs with the largest overall variance.

```{r}
trials = pData(mouseData)$diet
heatmapColColors = brewer.pal(12, "Set3")[as.integer(factor(trials))]
heatmapCols = colorRampPalette(brewer.pal(9, "RdBu"))(50)

#Plots the heatmap
plotMRheatmap(obj = mouseData, n = 200, cexRow = 0.4, cexCol = 0.4,
              trace = "none", col = heatmapCols, ColSideColors = heatmapColColors)

#plots the correlation map.
plotCorr(obj = mouseData, n = 200, cexRow = 0.25, cexCol = 0.25, 
         trace = "none", dendrogram = "none", col = heatmapCols)

```


How to create CMDS plots of the data and visually demonstrate the rarefaction 
effect at the OTU level:

```{r}
cl = factor(pData(mouseData)$diet)

#plotOrd - can load vegan and set distFun = vegdist and
#use dist.method = 'bray'
plotOrd(mouseData, tran = TRUE, usePCA = FALSE, useDist = TRUE, bg = cl, 
        pch = 21)

#plotRare
res = plotRare(mouseData, cl = cl, pch = 21, bg = cl)

#linear fits for plotRare / legend
tmp = lapply(levels(cl), function(lv) lm(res[, "ident"] ~ res[,"libSize"] -1,
                                         subset = cl == lv))
for(i in 1:length(levels(cl))) {
  abline(tmp[[i]], col = i)
}
legend("topleft", c("Diet 1", "Diet 2"), text.col = c(1,2),
       box.col = NA)
```

## 6.3: Feature Specific

If reads are clustered with high similarity, then they normally represent
functional or taxonomic units. Reads from one organism can possibly get clustered
into multiple OTUs. This can result in an overestimation of abundances.
Confirming differential abundance is extremely important to combat this. Features
can be plotted in multiple ways:

  -plotOTU: abundances of a particular feature by group
  -plotGenus: abundances for several features similarly annotated by group
  -plotFeature: abundances of a particular feature by group.
  
```{r}
head(MRtable(fit, coef = 2, taxa = 1:length(fData(lungTrim)$taxa)))

patients = sapply(strsplit(rownames(pData(lungTrim)), split = "_"),
                  function(i){
                    i[3]
                  })
pData(lungTrim)$patients = patients

classIndex = list(smoker = which(pData(lungTrim)$SmokingStatus == "Smoker"))
classIndex$nonsmoker = which(pData(lungTrim)$SmokingStatus == "NonSmoker")
otu = 779

#plotOTU
plotOTU(lungTrim, otu = otu, classIndex, main = "Neisseria meningitidis")

#Multiple OTUs annotated Similarly
x = fData(lungTrim)$taxa[otu]
otulist = grep(x, fData(lungTrim)$taxa)

#plotGenus
plotGenus(lungTrim, otulist, classIndex, labs = FALSE, main = "Neisseria meningitidis")

lablist <- c("S", "NS")
axis(1, at = seq(1,6, by = 1), labels = rep(lablist, times = 3))
```

```{r}
classIndex = list(Western = which(pData(mouseData)$diet == "Western"))
classIndex$BK = which(pData(mouseData)$diet == "BK")
otuIndex = 8770

#par(mfrow=c(1,2))
dates = pData(mouseData)$date

plotFeature(mouseData, norm = FALSE, log = FALSE, otuIndex, classIndex,
            col = dates, sortby = dates, ylab = "Raw reads")
```

# 7: Summary

To cite this package, use the following command:

```{r}
citation("metagenomeSeq")
```

