---
title: "Practicum 3"
output: html_notebook
editor_options: 
  markdown: 
    wrap: 72
---

Main objective: Determine what factors contribute to tip amount for NYC
taxi drivers.

#All libraries are allowed.

#Ask the TA:

- include full correlation matrix in Q1? 
- Can we swap feature engineering and feature selection?
- Show them correlation matrix, do they want the categorical variables one-hot encoded or left numeric?
- Can we combine Q1 and Q2?

Question 1:

Part 1: • Load the NYC Green Taxi Trip Records data into a data frame or tibble

```{r}
library(tidyverse)
library(caret)
library(psych)
library(FNN)
library(caTools)
library(Metrics)
library(car)
library(mltools)


tripdata.df <- read.csv("2018_Green_Taxi_Trip_Data.csv", header = TRUE)

```


Question 1 & 2: Data Understanding / Data Preparation - Distributions & Missing Values

The dimensions and distributions of the data set is displayed below, along with any missing values within the dataset. One column, ehail_fee, was completely missing and was removed entirely. The column "Trip type" is largely in-tact with only three missing values present, and missing values will be replaced with the most common type of trip (1).

Many errors arose while importing the data set which prevent the full assessment of each variable, and the following have been corrected below:
  
  -the columns fare_amount and total_amount are imported as the character class due to the presence of a comma in a few of 
   the numbers. These commas were removed using gsub() and the character values were converted to numeric.
  
  -lpep_pickup_datetime and lpep_dropoff_datetime were imported as characters, and are more useful if converted to the 
   POSIxct datetime class. That conversion is performed below.
   
  -The assignment requires us to analyze data from 2018, but there are several entries from other years within the dataset.
   Any date not from 2018 was removed using the filter() function from dplyr.
   
  -Per the data dictionary, tips are only entered into the data set during credit card transactions. The data has been 
   filtered by payment_type to only include credit card payments.
   
  -RatecodeID only has definitions for factors 1 through 6, yet there are a few values for value '99' present which are undefined
   in the dictionary. Unable to be defined, these values were removed from the data set using the filter() function in dplyr.
  
  -Many values are encoded within the dataset by a method which is not conducive to model construction. These variables are 
   decoded below for clarity and in preparation for one-hot encoding later in the model construction process.
   
   
The distribution of each variable is evaluated below, and used to evaluated the impact of different missing value and outlier
removal strategies. The x-axis of some variables with a heavy skew have been limited using xlim() to better display skewed shape
of the variable. 

A key observation is that over 60% of the data set is comprised of data where no tips are offered. If this were a classification
model to determine whether a driver was going to be tipped or not, this data would be extremely useful. However, in a regression
model it runs the risk of introducing a significant amount of noise.

It is also observed that many of the variables are strongly right-skewed, which is expected to improve once outliers are 
removed.

```{r}
#Summary Statistics
glimpse(tripdata.df)
dim(tripdata.df)
summary(tripdata.df)

#Count NA Values
for(i in 1:ncol(tripdata.df)){
  print(colnames(tripdata.df[i]))
  print(sum(is.na(tripdata.df[,i])))
  print(as.double(sum(is.na(tripdata.df[,i])) / nrow(tripdata.df)*100))
}

#Handling Missing Values
tripdata.clean <- tripdata.df %>%
  select(-ehail_fee) %>%
    mutate(trip_type = replace_na(trip_type, 1))

#Conversion of variables to numeric for use in model.
tripdata.clean <- tripdata.df %>%
  mutate(fare_amount = gsub(",", "", fare_amount)) %>%
    mutate(total_amount = gsub(",", "", total_amount)) %>%
      mutate(fare_amount = as.numeric(fare_amount)) %>%
        mutate(total_amount = as.numeric(total_amount)) %>%
      mutate(lpep_pickup_datetime = as.POSIXct(lpep_pickup_datetime, format = "%m/%d/%Y %H:%M")) %>%
    mutate(lpep_dropoff_datetime = as.POSIXct(lpep_dropoff_datetime, format = "%m/%d/%Y %H:%M"))


#Ensuring only dates from 2018, passenger count is at least 1, and payment type 
tripdata.clean <- tripdata.clean %>%
  filter(lpep_pickup_datetime < "1/1/2018" | lpep_dropoff_datetime > "5/1/2018") %>%
    filter(passenger_count >= 1) %>%
  filter(payment_type == 1)


#RatecodeID has few values logged as 99, which are not present in the data dictionary.
tripdata.clean <- tripdata.clean %>% filter(RatecodeID <= 6)

#Variable decoding
tripdata.clean <- tripdata.clean %>%
  mutate(across(c(VendorID,RatecodeID, payment_type, trip_type), as.factor))

levels(tripdata.clean$RatecodeID) <- c("Standard Rate", "JFK", "Newark", "Nassau or Westchester", "Negociated Rate", 
                                         "Group Ride", "NA")
levels(tripdata.clean$payment_type) <- c("Credit Card", "Cash", "No charge", "Dispute", "Unknown")
levels(tripdata.clean$VendorID) <- c("Creative Mobile Technologies", "VeriFone, INC")
levels(tripdata.clean$trip_type) <- c("Street-hail", "Dispatch")

#Distribution before outlier removal.
ggplot(data = tripdata.clean, mapping = aes(x = passenger_count)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(title = "Pre-Removal distribution of Passenger Count",
       caption = "2018 NYC Traffic data") +
  xlab("Passenger Count") +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = trip_distance)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(title = "Pre-Removal Distribution of Trip Distance",
       caption = "2018 NYC Traffic data") +
  xlab("Trip Distance") +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = fare_amount)) +
  geom_histogram(binwidth = 5, color = "black", fill = "lightblue") +
  labs(title = "Pre-Removal Distribution of Fare Amount",
       caption = "2018 NYC Traffic data") +
  xlab("Fare Amount") +
  xlim(0, 500) +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = tip_amount)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(title = "Pre-Removal Distribution of Tip Amount",
       caption = "2018 NYC Traffic data") +
  xlab("Tip Amount") +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = tolls_amount)) +
  geom_histogram(binwidth = 10, color = "black", fill = "lightblue") +
  labs(title = "Pre-Removal Distribution of Tolls Amount",
       caption = "2018 NYC Traffic data") +
  xlab("Tolls Amount") +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = total_amount)) +
  geom_histogram(binwidth = 10, color = "black", fill = "lightblue") +
  xlim(0, 500) +
  labs(title = "Pre-Removal Distribution of Total Amount",
       caption = "2018 NYC Traffic data") +
  xlab("Total Amount") +
  theme_bw()
```



Question 1 & 2: Data Understanding / Data Preparation - Outliers & Outlier Handling

For the development of this model, outlier values are defined as having a z-score of 3 or greater. The z-score for each
data point was calculated and plotted below. During data preparation, values with z-scores above this value will be removed
from the dataset.

```{r}
passenger.mean <- mean(tripdata.clean$passenger_count)
passenger.sd <- sd(tripdata.clean$passenger_count)
tripdata.clean$zpassenger_count <- abs((passenger.mean - tripdata.clean$passenger_count)/passenger.sd)

ggplot(data = tripdata.clean, mapping = aes(y = passenger_count)) +
  geom_boxplot() +
  theme_bw()
#----------------------------------------------------------------------------------------------------

distance.mean <- mean(tripdata.clean$trip_distance)
distance.sd <- sd(tripdata.clean$trip_distance)
tripdata.clean$ztrip_distance <- abs((distance.mean - tripdata.clean$trip_distance)/distance.sd)

ggplot(data = tripdata.clean, mapping = aes(y = trip_distance)) +
  geom_boxplot()+
  theme_bw()
#----------------------------------------------------------------------------------------------------

fare.mean <- mean(tripdata.clean$fare_amount)
fare.sd <- sd(tripdata.clean$fare_amount)
tripdata.clean$zfare_amount <- abs((fare.mean - tripdata.clean$fare_amount)/fare.sd)

ggplot(data = tripdata.clean, mapping = aes(y = fare_amount)) +
  geom_boxplot()+
  theme_bw()
#----------------------------------------------------------------------------------------------------
tip.mean <- mean(tripdata.clean$tip_amount)
tip.sd <- sd(tripdata.clean$tip_amount)
tripdata.clean$ztip_amount <- abs((tip.mean - tripdata.clean$tip_amount)/tip.sd)

ggplot(data = tripdata.clean, mapping = aes(y = tip_amount)) +
  geom_boxplot()+
  theme_bw()
#----------------------------------------------------------------------------------------------------
tolls.mean <- mean(tripdata.clean$tolls_amount)
tolls.sd <- sd(tripdata.clean$tolls_amount)
tripdata.clean$ztolls_amount <- abs((tolls.mean - tripdata.clean$tolls_amount)/tolls.sd)

ggplot(data = tripdata.clean, mapping = aes(y = tolls_amount)) +
  geom_boxplot()+
  theme_bw()
#----------------------------------------------------------------------------------------------------
total.mean <- mean(tripdata.clean$total_amount)
total.sd <- sd(tripdata.clean$total_amount)
tripdata.clean$ztotal_amount <- abs((total.mean - tripdata.clean$total_amount)/total.sd)

ggplot(data = tripdata.clean, mapping = aes(y = total_amount)) +
  geom_boxplot()+
  theme_bw()

tripdata.clean <- tripdata.clean %>%
  filter(zpassenger_count < 3) %>%
    filter(ztrip_distance < 3) %>%
      filter(zfare_amount < 3) %>% 
        filter(ztip_amount < 3) %>%
      filter(ztolls_amount < 3) %>%
    filter(ztotal_amount < 3) %>%
  select(!c(zpassenger_count, ztrip_distance, zfare_amount,
            ztip_amount, ztolls_amount, ztotal_amount))

```


After exclusion of missing values and outliers, the distribution of each variable is revisited before model creation.
Although skew is still present, removal of the outliers has drastically improved the distribution of these features.

```{R}
#Distributions after outlier removal
ggplot(data = tripdata.clean, mapping = aes(x = passenger_count)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(title = "Post-Removal distribution of Passenger Count",
       caption = "2018 NYC Traffic data") +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = trip_distance)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(title = "Post-Removal Distribution of Trip Distance",
       caption = "2018 NYC Traffic data") +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = fare_amount)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(title = "Post-Removal Distribution of Fare Amount",
       caption = "2018 NYC Traffic data") +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = tip_amount)) +
  geom_histogram(binwidth = 0.5, color = "black", fill = "lightblue") +
  labs(title = "Post-Removal Distribution of Tip Amount",
       caption = "2018 NYC Traffic data") +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = tolls_amount)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(title = "Post-Removal Distribution of Tolls Amount",
       caption = "2018 NYC Traffic data") +
  scale_y_log10() +
  theme_bw()

ggplot(data = tripdata.clean, mapping = aes(x = total_amount)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(title = "Post-Removal Distribution of Total Amount",
       caption = "2018 NYC Traffic data") +
  theme_bw()
```




Question 1: Data Understanding - Feature Engineering

Below we have used the datetime variables 'lpep_pickup_datetime' and 'lpep_dropoff_datetime' to calculate a novel variable
'trip time', which measures the duration of each trip. This not only integrates unusual classes into a numeric class which can
more easily be handled by the knn regression model and a weak positive correlation with tip amount, which will lend predicting strength to the model. 

During variable creation, outlier values with z scores greater than 3 were removed.

```{r}
#Feature Engineering: Trip Time
tripdata.clean <- tripdata.clean %>%
  mutate(trip_time = lpep_dropoff_datetime - lpep_pickup_datetime) %>%
    mutate(trip_time = as.character(trip_time)) %>%
  mutate(trip_time = as.numeric(trip_time))

time.mean <- mean(tripdata.clean$trip_time)
time.sd <- sd(tripdata.clean$trip_time)
tripdata.clean$ztrip_time <- abs((time.mean - tripdata.clean$trip_time)/time.sd)

tripdata.clean <- tripdata.clean %>%
  filter(ztrip_time < 3) %>%
  select(-ztrip_time)

ggplot(data = tripdata.clean, mapping = aes(x = trip_time)) +
  geom_histogram(binwidth = 0.2, color = "black", fill = "lightblue") +
  labs(title = "Distribution of Trip Time",
       caption = "2018 NYC Traffic data") +
  scale_x_log10() +
  theme_bw()

time.cor <- cor(x = tripdata.clean$trip_time, y = tripdata.clean$tip_amount, method = "pearson")
print(time.cor)

#Feature engineering: Month, Day, Trip speed. (value per person)
#Divide into morning noon, evening, night.

tripdata.clean$passenger_value <- (tripdata.clean$total_amount / tripdata.clean$passenger_count)
check.var <- dummyVars(~ passenger_count:total_amount, data = tripdata.clean)
new.data <- as.data.frame(predict(check.var, newdata = tripdata.clean))


```


Question 2: Data Preparation - Data Encoding & Normalization

For use in the regression model, the variables VendorID, store_and_fwd_flag, and trip_type will be encoded 
binomially where each option will be represented with either a 0 or 1. The variables RatecodeID and payment_type are encoded
with one-hot encoding. Min-max normalization and one-hot Encoding is performed below:

```{r}
#Data normalization 
process <- preProcess(as.data.frame(tripdata.clean), method = c("range"))
tripdata.clean <- predict(process, as.data.frame(tripdata.clean))

#Data Encoding
tripdata.clean$VendorID <- ifelse(tripdata.clean$VendorID == "Creative Mobile Technologies", 0, 1)
tripdata.clean$store_and_fwd_flag <- ifelse(tripdata.clean$store_and_fwd_flag == "N", 0, 1)
tripdata.clean$trip_type <- ifelse(tripdata.clean$trip_type == "Street-hail", 0, 1)

dummy <- dummyVars(" ~ .", data = tripdata.clean)
tripdata.clean <- data.frame(predict(dummy, newdata = tripdata.clean))

initial.correlation.matrix <- cor(tripdata.clean)
head(initial.correlation.matrix)
```

The one-hot encoding technique results in many dummy variables with little to no variance. In order to properly evaluate each feature
for model development, the caret package function nearZeroVar() was called to remove non-applicable features. Below is the correlation
matrix of all remaining variables.

The datetime class objects were removed, as the data in these variables is captured in the engineered variable "trip_time". 
It can also be seen that the vast majority of RatecodeIDs belong to 'standard rate'. As this variable essentially functions as a 
constant, it is also removed from the correlation analysis.

```{R}
near.zero <- nearZeroVar(tripdata.clean, names = TRUE)

tripdata.clean <- tripdata.clean %>%
  select(-near.zero) %>%
  select(-lpep_pickup_datetime, -lpep_dropoff_datetime)


summary(tripdata.clean)
```

With all of the features placed on a comparible 

```{R}
#Identify correlations between variables 
#Show RatecodeIDs


correlation.matrix <- cor(tripdata.clean)
print(correlation.matrix)

#Justification for dropping 
print(table(tripdata.clean$RatecodeID.Standard.Rate))
```

Question 1 / Question 2: Data Understanding / Data Preparation -  Feature Selection 

```{R}
tripdata.clean

tip.model <- lm(formula = tip_amount ~ total_amount, data = tripdata.clean)
summary(tip.model)

tip.model <- lm(formula = tip_amount ~ total_amount+trip_time, data = tripdata.clean)
summary(tip.model)

tip.model <- lm(formula = tip_amount ~ total_amount+trip_time+trip_distance, data = tripdata.clean)
summary(tip.model)

#DOLocationID insignificant
tip.model <- lm(formula = tip_amount ~ total_amount+trip_time+trip_distance+DOLocationID, data = tripdata.clean)
summary(tip.model)

tip.model <- lm(formula = tip_amount ~ total_amount+trip_time+trip_distance+PULocationID, data = tripdata.clean)
summary(tip.model)

tripdata.clean <- tripdata.clean %>%
  select(total_amount, trip_time, trip_distance, PULocationID, tip_amount)

```


Question 2: Data Preparation - Modeling Preparation

Data is randomly and proportionally split below on a 80:20 split ratio, where 80% of the tidied and filtered data is devoted to the 
training data set, while 20% of the data is devoted to the validation data set. 

```{r}
set.seed(784)

sample <- sample.split(tripdata.clean$tip_amount, SplitRatio = 0.8)
training.data <- subset(tripdata.clean, sample == TRUE)
testing.data <- subset(tripdata.clean, sample == FALSE)
```




#You think we should manually calculate RMSE?
#MSE and MAE
```{r}
#Use regression model to predict 

knn.predict <- function(data_train, data_test, k){
  training.x <- data_train %>%
    select(-tip_amount)
  
  training.y <- data_train %>%
    select(tip_amount)
  
  testing.x <- data_test %>%
    select(-tip_amount)
  
  testing.y <- data_test %>%
    select(tip_amount)
  
  pred.tip <- FNN::knn.reg(train = training.x, test = testing.x, y = training.y, k = k)
  print(str(pred.tip))
  
  testing.y.results <- testing.y
  testing.y.results$k.pred <- pred.tip$pred
  
  rmse <- rmse(testing.y.results$tip_amount, testing.y.results$k.pred)
  return(rmse)
}

pred <- knn.predict(training.data, testing.data, 3)
```

Question 4: • Provide at least 20 different values of k to the knn.predict() function (along with the training set 
and the test set)


```{r}
k.range <- seq(29, 49, by = 2)

for(k in k.range){
 k.value <- c(k.value, knn.predict(training.data, testing.data, k))
}

knn.df <- data.frame(k.range, k.value)
```


